{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n  4710400/170498071 [..............................] - ETA: 14:54"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import regularizers\n",
    "import ssl\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()\n",
    "\n",
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(32,32,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())##BatchNormalization\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(BatchNormalization())##BatchNormalization\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(100,activation='relu',kernel_regularizer=regularizers.l2(l=0.001))) ##regularizers\n",
    "classifier.add(BatchNormalization()) ##BatchNormalization\n",
    "classifier.add(Dropout(0.5)) ##Dropout\n",
    "\n",
    "classifier.add(Dense(100,activation='relu',kernel_regularizer=regularizers.l2(0.001)))##regularizers\n",
    "classifier.add(BatchNormalization()) ##BatchNormalization\n",
    "\n",
    "classifier.add(Dropout(0.3))##Dropout\n",
    "\n",
    "classifier.add(Dense(10,activation='softmax'))\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator ##Augmentation\n",
    "img_gen = ImageDataGenerator( featurewise_center=True,featurewise_std_normalization=True,rotation_range=10,width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True,vertical_flip=False,dtype=np.float32)\n",
    "img_gen.fit(x_train)\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='test_loss', patience=8, verbose=1) ##earlystop\n",
    "\n",
    "##開始訓練\n",
    "classifier.fit_generator(img_gen.flow(x_train, y_train, batch_size=100) ,steps_per_epoch=500,\n",
    "                               epochs=1, validation_data = (x_test, y_test),callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上方有用到一些避免Overfitting 的方法，有興趣的學員們可以參考這篇Medium:https://medium.com/@CinnamonAITaiwan/cnn%E5%85%A5%E9%96%80-overfitting-d10acd15ec21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[5.0641526e-02, 1.0562579e-04, 5.5907631e-01, 2.9860577e-02,\n        2.5437945e-01, 3.8103215e-02, 2.2494614e-02, 1.3636437e-03,\n        4.3736003e-02, 2.3901864e-04]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "mean_train = np.mean(x_train,axis=(0,1,2,3))\n",
    "std_train = np.std(x_train,axis=(0,1,2,3))\n",
    "\n",
    "input_example=(np.zeros(shape=(1,32,32,3)) -mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}